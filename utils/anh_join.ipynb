{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfcca4bb",
   "metadata": {},
   "source": [
    "\n",
    "# Combine `train/predictions.csv` Across Subfolders\n",
    "\n",
    "This utility does exactly the following, in a **simple** way:\n",
    "\n",
    "- For each subfolder inside a chosen *base folder* (e.g., \"anh's folder\"),\n",
    "- Open `./train/predictions.csv` in that subfolder,\n",
    "- Add an `event` column based on the subfolder name,\n",
    "- Combine all rows together,\n",
    "- Rename `pred` column to `label`,\n",
    "- Save the result as a single TSV file.\n",
    "\n",
    "> Edit the `BASE_FOLDER` and `OUTPUT_TSV` variables below and run the cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8d5d42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gd3470\\Desktop\\ssl\\utils\n",
      "Loaded: ..\\data\\humaid\\anh_4o\\california_wildfires_2018\\train\\gpt-4o-mini\\20251021-222139-modeS-RULES1-ALT\\predictions.csv  (rows: 5163)\n",
      "Loaded: ..\\data\\humaid\\anh_4o\\canada_wildfires_2016\\train\\gpt-4o-mini\\20251021-202956-modeS-RULES1-TIER1\\predictions.csv  (rows: 1569)\n",
      "Loaded: ..\\data\\humaid\\anh_4o\\cyclone_idai_2019\\train\\gpt-4o-mini\\20251021-205521-modeS-RULES1-TIER1\\predictions.csv  (rows: 2753)\n",
      "Loaded: ..\\data\\humaid\\anh_4o\\hurricane_dorian_2019\\train\\gpt-4o-mini\\20251021-224703-modeS-RULES1-ALT\\predictions.csv  (rows: 5329)\n",
      "Loaded: ..\\data\\humaid\\anh_4o\\hurricane_florence_2018\\train\\gpt-4o-mini\\20251021-212048-modeS-RULES1-ALT\\predictions.csv  (rows: 4384)\n",
      "Loaded: ..\\data\\humaid\\anh_4o\\hurricane_harvey_2017\\train\\gpt-4o-mini\\20251022-001305-modeS-RULES1-ALT\\predictions.csv  (rows: 6378)\n",
      "Loaded: ..\\data\\humaid\\anh_4o\\hurricane_irma_2017\\train\\gpt-4o-mini\\20251022-004334-modeS-RULES1-ALT\\predictions.csv  (rows: 6579)\n",
      "Loaded: ..\\data\\humaid\\anh_4o\\hurricane_maria_2017\\train\\gpt-4o-mini\\20251021-215113-modeS-RULES1-ALT\\predictions.csv  (rows: 5094)\n",
      "Loaded: ..\\data\\humaid\\anh_4o\\kaikoura_earthquake_2016\\train\\gpt-4o-mini\\20251021-182421-modeS-RULES1-TIER1\\predictions.csv  (rows: 1536)\n",
      "Loaded: ..\\data\\humaid\\anh_4o\\kerala_floods_2018\\train\\gpt-4o-mini\\20251021-231731-modeS-RULES1-ALT\\predictions.csv  (rows: 5588)\n",
      "Saved combined TSV to: C:\\Users\\gd3470\\Desktop\\ssl\\utils\\all_events.tsv\n",
      "              tweet_id                                         tweet_text  \\\n",
      "0  1061651759158853632  Smoking ruins and a mobile DNA lab: California...   \n",
      "1  1064599072151990273  Californiaâ€™s utility, PG&amp;E was responsible...   \n",
      "2  1061239977282072577  At least 9 dead in California wildfires as ten...   \n",
      "3  1063608886995898368  RT @WGNNews: At least 66 dead in California wi...   \n",
      "4  1064157198350086145  25K - + homeless &amp; from the #DeranfgedOran...   \n",
      "\n",
      "                  class_label                              label  confidence  \\\n",
      "0      injured_or_dead_people             injured_or_dead_people         0.9   \n",
      "1  other_relevant_information  infrastructure_and_utility_damage         0.9   \n",
      "2      injured_or_dead_people             injured_or_dead_people         0.9   \n",
      "3      injured_or_dead_people             injured_or_dead_people         0.9   \n",
      "4      injured_or_dead_people             injured_or_dead_people         0.9   \n",
      "\n",
      "   entropy                      event  \n",
      "0      NaN  california_wildfires_2018  \n",
      "1      NaN  california_wildfires_2018  \n",
      "2      NaN  california_wildfires_2018  \n",
      "3      NaN  california_wildfires_2018  \n",
      "4      NaN  california_wildfires_2018  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# === USER SETTINGS ===\n",
    "# Set the path to the base folder that contains event subfolders (each with ./train/predictions.csv)\n",
    "BASE_FOLDER = Path(r\"..\\data\\humaid\\anh_4o\")  # <- change me\n",
    "OUTPUT_TSV = Path(\"./all_events.tsv\")  # where to save the combined TSV\n",
    "\n",
    "def get_first_subfolder(path_obj):\n",
    "    \"\"\"\n",
    "    Returns the first subfolder found within a given pathlib.Path object.\n",
    "    Returns None if no subfolders are found.\n",
    "    \"\"\"\n",
    "    for item in path_obj.iterdir():\n",
    "        if item.is_dir():\n",
    "            return item\n",
    "    return None\n",
    "\n",
    "def combine_predictions(base_folder: Path, output_tsv: Path):\n",
    "    base_folder = Path(base_folder)\n",
    "    all_rows = []\n",
    "    subfolders = [p for p in base_folder.iterdir() if p.is_dir()]\n",
    "    if not subfolders:\n",
    "        print(f\"No subfolders found in: {base_folder}\")\n",
    "        return\n",
    "\n",
    "    for sub in sorted(subfolders):\n",
    "        pred_csv = get_first_subfolder(sub / \"train\" / \"gpt-4o-mini\") / \"predictions.csv\"\n",
    "        if not pred_csv.exists():\n",
    "            print(f\"Skipping (missing file): {pred_csv}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(pred_csv)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read {pred_csv}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Add event column from the subfolder name\n",
    "        df[\"event\"] = sub.name\n",
    "\n",
    "        # Rename 'pred' -> 'label' if present\n",
    "        if \"predicted_label\" in df.columns and \"label\" not in df.columns:\n",
    "            df = df.rename(columns={\"predicted_label\": \"label\"})\n",
    "\n",
    "        all_rows.append(df)\n",
    "        print(f\"Loaded: {pred_csv}  (rows: {len(df)})\")\n",
    "\n",
    "    if not all_rows:\n",
    "        print(\"No prediction files were loaded. Nothing to combine.\")\n",
    "        return\n",
    "\n",
    "    combined = pd.concat(all_rows, ignore_index=True)\n",
    "\n",
    "    # Ensure final column is named 'label' (if neither 'pred' nor 'label' existed, we do nothing)\n",
    "    # If both existed, we keep 'label' and drop 'pred' to avoid duplicates.\n",
    "    if \"predicted_label\" in combined.columns and \"label\" in combined.columns:\n",
    "        combined = combined.drop(columns=[\"predicted_label\"])\n",
    "\n",
    "    combined.to_csv(output_tsv, sep=\"\\t\", index=False)\n",
    "    print(f\"Saved combined TSV to: {output_tsv.resolve()}\")\n",
    "    return combined\n",
    "\n",
    "# Run the utility\n",
    "import os\n",
    "print(os.getcwd())\n",
    "combined_df = combine_predictions(BASE_FOLDER, OUTPUT_TSV)\n",
    "if combined_df is not None:\n",
    "    print(combined_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
