{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd892375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from pathlib import Path\n",
    "\n",
    "my_df = pd.read_csv(r'..\\data\\humaid\\plabel\\train\\union.tsv', sep='\\t')\n",
    "their_folder = Path(\"..\\data\\humaid\\k_zero_shot\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "for event_file in their_folder.glob(\"*.tsv\"):\n",
    "    their_df = pd.read_csv(event_file, sep='\\t')\n",
    "    event = '_'.join(event_file.stem.split('_')[:3])\n",
    "\n",
    "    merged = pd.merge(my_df[my_df['event'] == event], their_df, on='tweet_id')\n",
    "    merged = merged[['class_label', 'label', 'gpt5_label']]\n",
    "\n",
    "    my_f1 = f1_score(merged['class_label'], merged['label'], average='macro')\n",
    "    their_f1 = f1_score(merged['class_label'], merged['gpt5_label'], average='macro')\n",
    "\n",
    "    rows.append({'event': event, 'mine': my_f1, 'theirs': their_f1})\n",
    "\n",
    "pd.DataFrame(rows).to_clipboard()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934e80bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing event: california_wildfires_2018 (10 tweets) | Labels: ['missing_or_found_people', 'sympathy_and_support', 'not_humanitarian', 'rescue_volunteering_or_donation_effort']\n",
      "Processing event: hurricane_dorian_2019 (8 tweets) | Labels: ['displaced_people_and_evacuations', 'not_humanitarian', 'sympathy_and_support', 'caution_and_advice', 'rescue_volunteering_or_donation_effort']\n",
      "Processing event: hurricane_florence_2018 (1 tweets) | Labels: ['infrastructure_and_utility_damage']\n",
      "Processing event: hurricane_irma_2017 (5 tweets) | Labels: ['caution_and_advice', 'infrastructure_and_utility_damage', 'injured_or_dead_people']\n",
      "Processing event: hurricane_maria_2017 (11 tweets) | Labels: ['rescue_volunteering_or_donation_effort', 'injured_or_dead_people', 'sympathy_and_support', 'infrastructure_and_utility_damage']\n",
      "Processing event: kerala_floods_2018 (5 tweets) | Labels: ['rescue_volunteering_or_donation_effort', 'injured_or_dead_people']\n",
      "Done. Saved to ../gpt4o_mini_predictions.tsv.\n"
     ]
    }
   ],
   "source": [
    "# Normal\n",
    "\n",
    "from openai import OpenAI\n",
    "import csv, pandas as pd\n",
    "import os, time, random\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- Initialize API client ---\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# --- Load HumAID test data ---\n",
    "gold_table = pd.read_csv(\n",
    "    \"../data/humaid/joined/test.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    quoting=csv.QUOTE_NONE\n",
    ")\n",
    "gold_table = gold_table[gold_table[\"class_label\"] != \"other_relevant_information\"].reset_index(drop=True)\n",
    "# FOR TESTING\n",
    "gold_table = gold_table.sample(n=40, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# --- Define category definitions ---\n",
    "CATEGORY_DEFINITIONS = {\n",
    "    \"caution_and_advice\": \"Reports of warnings issued or lifted, guidance and tips related to the disaster.\",\n",
    "    \"sympathy_and_support\": \"Tweets with prayers, thoughts, and emotional support.\",\n",
    "    \"requests_or_urgent_needs\": \"Reports of urgent needs or supplies such as food, water, clothing, money, etc.\",\n",
    "    \"displaced_people_and_evacuations\": \"People who have relocated due to the crisis, even for a short time.\",\n",
    "    \"injured_or_dead_people\": \"Reports of injured or dead people due to the disaster.\",\n",
    "    \"missing_or_found_people\": \"Reports of missing or found people due to the disaster.\",\n",
    "    \"infrastructure_and_utility_damage\": \"Reports of any type of damage to infrastructure such as buildings, houses, roads, power lines, etc.\",\n",
    "    \"rescue_volunteering_or_donation_effort\": \"Reports of any type of rescue, volunteering, or donation efforts.\",\n",
    "    \"not_humanitarian\": \"If the tweet does not convey humanitarian aid-related information.\"\n",
    "}\n",
    "\n",
    "# --- Dynamic prompt generator ---\n",
    "def make_prompt(tweet_text, event_labels):\n",
    "    label_defs = \"\\n\".join([\n",
    "        f\"- {label.replace('_', ' ').title()}: {CATEGORY_DEFINITIONS[label]}\"\n",
    "        for label in event_labels\n",
    "    ])\n",
    "    return f\"\"\"Read the category names and their definitions below, then classify the following tweet into the appropriate category. \n",
    "In your response, mention only the category name.\n",
    "\n",
    "Category name: category definition\n",
    "{label_defs}\n",
    "\n",
    "Tweet: {tweet_text}\n",
    "Category:\"\"\"\n",
    "\n",
    "# --- Classifier function ---\n",
    "def classify_tweet(tweet, event_labels, max_retries=3):\n",
    "    prompt = make_prompt(tweet, event_labels)\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0,\n",
    "                max_tokens=10,\n",
    "            )\n",
    "            return response.choices[0].message.content.strip().replace(' ', '_').lower()\n",
    "        except Exception as e:\n",
    "            wait = 2 ** attempt + random.random()\n",
    "            print(f\"Error: {e} — retrying in {wait:.1f}s\")\n",
    "            time.sleep(wait)\n",
    "    return \"ERROR\"\n",
    "\n",
    "# --- Run predictions grouped by event ---\n",
    "labels = []\n",
    "for event_name, event_df in gold_table.groupby(\"event\"):\n",
    "    # Determine which labels exist in this event\n",
    "    event_labels = event_df[\"class_label\"].str.replace(\" \", \"_\").str.lower().unique().tolist()\n",
    "    event_labels = [lbl for lbl in event_labels if lbl in CATEGORY_DEFINITIONS]\n",
    "\n",
    "    print(f\"Processing event: {event_name} ({len(event_df)} tweets) | Labels: {event_labels}\")\n",
    "\n",
    "    for i, row in event_df.iterrows():\n",
    "        pred = classify_tweet(str(row[\"tweet_text\"]), event_labels)\n",
    "        if pred == \"ERROR\":\n",
    "            raise RuntimeError(f\"Error encountered at row {i}. Stopping run.\")\n",
    "        labels.append(pred)\n",
    "        if (len(labels)) % 50 == 0:\n",
    "            print(f\"Processed {len(labels)}/{len(gold_table)} tweets...\")\n",
    "            pd.DataFrame({\"tweet_text\": gold_table[\"tweet_text\"][:len(labels)], \"prediction\": labels}).to_csv(\n",
    "                \"../gpt4o_mini_predictions_partial2.tsv\", index=False, sep=\"\\t\"\n",
    "            )\n",
    "\n",
    "# --- Save final predictions ---\n",
    "gold_table[\"prediction\"] = labels\n",
    "gold_table.to_csv(\"../gpt4o_mini_predictions2.tsv\", index=False, sep=\"\\t\")\n",
    "print(\"Done. Saved to ../gpt4o_mini_predictions2.tsv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd99935d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing event: california_wildfires_2018 (10 tweets) | Labels: ['missing_or_found_people', 'sympathy_and_support', 'not_humanitarian', 'rescue_volunteering_or_donation_effort']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing event: hurricane_dorian_2019 (8 tweets) | Labels: ['displaced_people_and_evacuations', 'not_humanitarian', 'sympathy_and_support', 'caution_and_advice', 'rescue_volunteering_or_donation_effort']\n",
      "Processing event: hurricane_florence_2018 (1 tweets) | Labels: ['infrastructure_and_utility_damage']\n",
      "Processing event: hurricane_irma_2017 (5 tweets) | Labels: ['caution_and_advice', 'infrastructure_and_utility_damage', 'injured_or_dead_people']\n",
      "Processing event: hurricane_maria_2017 (11 tweets) | Labels: ['rescue_volunteering_or_donation_effort', 'injured_or_dead_people', 'sympathy_and_support', 'infrastructure_and_utility_damage']\n",
      "Processing event: kerala_floods_2018 (5 tweets) | Labels: ['rescue_volunteering_or_donation_effort', 'injured_or_dead_people']\n",
      "Done. Saved to ../gpt4o_mini_predictions2.tsv.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import csv, pandas as pd\n",
    "import os, time, random, json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- Initialize API client ---\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# --- Load HumAID test data ---\n",
    "gold_table = pd.read_csv(\n",
    "    \"../data/humaid/joined/test.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    quoting=csv.QUOTE_NONE\n",
    ")\n",
    "gold_table = gold_table[gold_table[\"class_label\"] != \"other_relevant_information\"].reset_index(drop=True)\n",
    "\n",
    "# FOR TESTING\n",
    "gold_table = gold_table.sample(n=40, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# --- Define category definitions ---\n",
    "CATEGORY_DEFINITIONS = {\n",
    "    \"caution_and_advice\": \"Reports of warnings issued or lifted, guidance and tips related to the disaster.\",\n",
    "    \"sympathy_and_support\": \"Tweets with prayers, thoughts, and emotional support.\",\n",
    "    \"requests_or_urgent_needs\": \"Reports of urgent needs or supplies such as food, water, clothing, money, etc.\",\n",
    "    \"displaced_people_and_evacuations\": \"People who have relocated due to the crisis, even for a short time.\",\n",
    "    \"injured_or_dead_people\": \"Reports of injured or dead people due to the disaster.\",\n",
    "    \"missing_or_found_people\": \"Reports of missing or found people due to the disaster.\",\n",
    "    \"infrastructure_and_utility_damage\": \"Reports of any type of damage to infrastructure such as buildings, houses, roads, power lines, etc.\",\n",
    "    \"rescue_volunteering_or_donation_effort\": \"Reports of any type of rescue, volunteering, or donation efforts.\",\n",
    "    \"not_humanitarian\": \"If the tweet does not convey humanitarian aid-related information.\"\n",
    "}\n",
    "\n",
    "# --- Dynamic prompt generator ---\n",
    "def make_prompt(tweet_text, event_labels):\n",
    "    label_defs = \"\\n\".join([\n",
    "        f\"- {label.replace('_', ' ').title()}: {CATEGORY_DEFINITIONS[label]}\"\n",
    "        for label in event_labels\n",
    "    ])\n",
    "    valid_list = \", \".join(event_labels)\n",
    "    return f\"\"\"Classify the following tweet into ONE of the valid categories listed below.\n",
    "\n",
    "Category name: category definition\n",
    "{label_defs}\n",
    "\n",
    "Return ONLY a valid label from this JSON format:\n",
    "{{\"category\": \"<one of [{valid_list}]>\"}}\n",
    "\n",
    "Tweet: {tweet_text}\"\"\"\n",
    "\n",
    "# --- Classifier function ---\n",
    "def classify_tweet(tweet, event_labels, max_retries=3):\n",
    "    prompt = make_prompt(tweet, event_labels)\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                temperature=0,\n",
    "                max_tokens=20,\n",
    "            )\n",
    "            content = response.choices[0].message.content\n",
    "            data = json.loads(content)\n",
    "            label = data.get(\"category\", \"\").strip().lower()\n",
    "            if label not in event_labels:\n",
    "                raise ValueError(f\"Invalid label '{label}' returned\")\n",
    "            return label\n",
    "        except Exception as e:\n",
    "            wait = 2 ** attempt + random.random()\n",
    "            print(f\"Error: {e} — retrying in {wait:.1f}s\")\n",
    "            time.sleep(wait)\n",
    "    return \"ERROR\"\n",
    "\n",
    "# --- Run predictions grouped by event ---\n",
    "labels = []\n",
    "for event_name, event_df in gold_table.groupby(\"event\"):\n",
    "    event_labels = event_df[\"class_label\"].str.replace(\" \", \"_\").str.lower().unique().tolist()\n",
    "    event_labels = [lbl for lbl in event_labels if lbl in CATEGORY_DEFINITIONS]\n",
    "\n",
    "    print(f\"Processing event: {event_name} ({len(event_df)} tweets) | Labels: {event_labels}\")\n",
    "\n",
    "    for i, row in event_df.iterrows():\n",
    "        pred = classify_tweet(str(row[\"tweet_text\"]), event_labels)\n",
    "        if pred == \"ERROR\":\n",
    "            raise RuntimeError(f\"Error encountered at row {i}. Stopping run.\")\n",
    "        labels.append(pred)\n",
    "        if (len(labels)) % 50 == 0:\n",
    "            print(f\"Processed {len(labels)}/{len(gold_table)} tweets...\")\n",
    "            pd.DataFrame({\"tweet_text\": gold_table[\"tweet_text\"][:len(labels)], \"prediction\": labels}).to_csv(\n",
    "                \"../gpt4o_mini_predictions_partial2.tsv\", index=False, sep=\"\\t\"\n",
    "            )\n",
    "\n",
    "# --- Save final predictions ---\n",
    "gold_table[\"prediction\"] = labels\n",
    "gold_table.to_csv(\"../gpt4o_mini_predictions2.tsv\", index=False, sep=\"\\t\")\n",
    "print(\"Done. Saved to ../gpt4o_mini_predictions2.tsv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f44f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool Calling\n",
    "from openai import OpenAI\n",
    "import csv, pandas as pd\n",
    "import os, time, random, json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- Initialize API client ---\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# --- Load HumAID test data ---\n",
    "gold_table = pd.read_csv(\n",
    "    \"../data/humaid/joined/test.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    quoting=csv.QUOTE_NONE\n",
    ")\n",
    "gold_table = gold_table[gold_table[\"class_label\"] != \"other_relevant_information\"].reset_index(drop=True)\n",
    "gold_table = gold_table.sample(n=40, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# --- Define category definitions ---\n",
    "CATEGORY_DEFINITIONS = {\n",
    "    \"caution_and_advice\": \"Reports of warnings issued or lifted, guidance and tips related to the disaster.\",\n",
    "    \"sympathy_and_support\": \"Tweets with prayers, thoughts, and emotional support.\",\n",
    "    \"requests_or_urgent_needs\": \"Reports of urgent needs or supplies such as food, water, clothing, money, etc.\",\n",
    "    \"displaced_people_and_evacuations\": \"People who have relocated due to the crisis, even for a short time.\",\n",
    "    \"injured_or_dead_people\": \"Reports of injured or dead people due to the disaster.\",\n",
    "    \"missing_or_found_people\": \"Reports of missing or found people due to the disaster.\",\n",
    "    \"infrastructure_and_utility_damage\": \"Reports of any type of damage to infrastructure such as buildings, houses, roads, power lines, etc.\",\n",
    "    \"rescue_volunteering_or_donation_effort\": \"Reports of any type of rescue, volunteering, or donation efforts.\",\n",
    "    \"not_humanitarian\": \"If the tweet does not convey humanitarian aid-related information.\"\n",
    "}\n",
    "\n",
    "# --- Function schema for tool calling ---\n",
    "def make_classification_tool(event_labels):\n",
    "    return {\n",
    "        \"name\": \"classify_tweet\",\n",
    "        \"description\": \"Selects the best-matching humanitarian category for a tweet.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"label\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": event_labels\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"label\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "# --- Classifier function using function calling ---\n",
    "def classify_tweet(tweet, event_labels, max_retries=3):\n",
    "    prompt = (\n",
    "        \"Read the category names and their definitions below, then classify the following tweet \"\n",
    "        \"into one of the allowed categories.\\n\\n\"\n",
    "        + \"\\n\".join([f\"- {label}: {CATEGORY_DEFINITIONS[label]}\" for label in event_labels])\n",
    "        + f\"\\n\\nTweet: {tweet}\\nReturn one of: {event_labels}\"\n",
    "    )\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                tools=[{\"type\": \"function\", \"function\": make_classification_tool(event_labels)}],\n",
    "                tool_choice={\"type\": \"function\", \"function\": {\"name\": \"classify_tweet\"}},\n",
    "                temperature=0,\n",
    "            )\n",
    "\n",
    "            tool_call = response.choices[0].message.tool_calls[0]\n",
    "            args = json.loads(tool_call.function.arguments)\n",
    "            label = args[\"label\"].strip().lower()\n",
    "            if label in event_labels:\n",
    "                return label\n",
    "            print(f\"Invalid label '{label}', retrying...\")\n",
    "        except Exception as e:\n",
    "            wait = 2 ** attempt + random.random()\n",
    "            print(f\"Error: {e} — retrying in {wait:.1f}s\")\n",
    "            time.sleep(wait)\n",
    "    return \"ERROR\"\n",
    "\n",
    "# --- Run predictions grouped by event ---\n",
    "labels = []\n",
    "for event_name, event_df in gold_table.groupby(\"event\"):\n",
    "    event_labels = event_df[\"class_label\"].str.replace(\" \", \"_\").str.lower().unique().tolist()\n",
    "    event_labels = [lbl for lbl in event_labels if lbl in CATEGORY_DEFINITIONS]\n",
    "\n",
    "    print(f\"Processing event: {event_name} ({len(event_df)} tweets) | Labels: {event_labels}\")\n",
    "\n",
    "    for i, row in event_df.iterrows():\n",
    "        pred = classify_tweet(str(row[\"tweet_text\"]), event_labels)\n",
    "        if pred == \"ERROR\":\n",
    "            raise RuntimeError(f\"Error encountered at row {i}. Stopping run.\")\n",
    "        labels.append(pred)\n",
    "        if len(labels) % 50 == 0:\n",
    "            print(f\"Processed {len(labels)}/{len(gold_table)} tweets...\")\n",
    "            pd.DataFrame({\"tweet_text\": gold_table[\"tweet_text\"][:len(labels)], \"prediction\": labels}).to_csv(\n",
    "                \"../gpt4o_mini_predictions_partial2.tsv\", index=False, sep=\"\\t\"\n",
    "            )\n",
    "\n",
    "# --- Save final predictions ---\n",
    "gold_table[\"prediction\"] = labels\n",
    "gold_table.to_csv(\"../gpt4o_mini_predictions2.tsv\", index=False, sep=\"\\t\")\n",
    "print(\"Done. Saved to ../gpt4o_mini_predictions2.tsv.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
